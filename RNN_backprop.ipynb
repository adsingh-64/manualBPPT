{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x222a449c150>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to compare manual and PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    \"\"\"\n",
    "    Compare manual gradients (dt) with PyTorch autograd gradients (t.grad).\n",
    "\n",
    "    Args:\n",
    "        s (str): Description or name of the gradient being compared.\n",
    "        dt (torch.Tensor): Manually computed gradient.\n",
    "        t (torch.Tensor): PyTorch tensor with autograd gradient.\n",
    "\n",
    "    Prints:\n",
    "        Comparison results including exact match, approximate match, and maximum difference.\n",
    "    \"\"\"\n",
    "    exact = torch.all(dt == t.grad).item()\n",
    "    approx = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(\n",
    "        f\"{s:15s} | exact: {str(exact):5s} | approximate: {str(approx):5s} | maxdiff: {maxdiff:.6f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tiny Shakespeare Data\n",
    "# ------------------------------------------------------------------------------------\n",
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [\n",
    "    stoi[c] for c in s\n",
    "]  # encoder: take a string, output a list of integers\n",
    "decode = lambda l: \"\".join(\n",
    "    [itos[i] for i in l]\n",
    ")  # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# Model Variables\n",
    "# ---------------------------------------------------------------------------------\n",
    "vocab_size = len(itos)\n",
    "block_size = 8\n",
    "d_model = 24  # embedding dimension\n",
    "n_hidden = 200\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    if split == \"train\":\n",
    "        data = train_data\n",
    "        ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "        x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "        y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    else:\n",
    "        data = val_data\n",
    "        ix = torch.arange(len(data) - block_size)\n",
    "        x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "        y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_hidden, block_size):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_hidden = n_hidden\n",
    "        self.block_size = block_size\n",
    "        self.C = nn.Embedding(self.vocab_size, self.d_model)\n",
    "        self.U = nn.Linear(self.d_model, self.n_hidden, bias=True)\n",
    "        self.W = nn.Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.tan = nn.Tanh()\n",
    "        self.V = nn.Linear(n_hidden, vocab_size, bias=True)\n",
    "        self.h_0 = 0.1 * torch.ones(1, n_hidden)\n",
    "\n",
    "    def forward(self, xb, targets):\n",
    "        B, T = xb.shape\n",
    "        emb = self.C(xb)  # [B, T, d_model]\n",
    "        h_t = self.h_0.to(xb.device)\n",
    "        h_all = torch.zeros(B, T, n_hidden, device=xb.device)\n",
    "        intermediate_tensors = []\n",
    "        intermediate_embeddings = []\n",
    "        for t in range(T):\n",
    "            x_t = emb[:, t, :]  # [B, d_model]\n",
    "            intermediate_embeddings.extend([x_t])\n",
    "            a_t = self.U(x_t) + self.W(h_t)  # [B, n_hidden]\n",
    "            h_t = self.tan(a_t)  # [B, n_hidden]\n",
    "            h_all[:, t, :] = h_t\n",
    "            h_t.retain_grad()\n",
    "            intermediate_tensors.extend([h_t])\n",
    "        logits = self.V(h_all) # broadcast\n",
    "        logits.retain_grad()\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), targets.view(-1))\n",
    "        return logits, loss, intermediate_embeddings, intermediate_tensors\n",
    "\n",
    "    def get_parameters(self):\n",
    "        b = self.U.bias\n",
    "        c = self.V.bias\n",
    "        return b, c, self.C.weight, self.U.weight, self.W.weight, self.V.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "model = CharRNN(vocab_size, d_model, n_hidden, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass and get PyTorch grads\n",
    "xb, yb = get_batch(\"train\")\n",
    "logits, loss, intermediate_embeddings, intermediate_tensors = model(xb, yb)\n",
    "b, c, C, U, W, V = model.get_parameters()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we manually compute the gradients (see derivations.pdf), and use the function \n",
    "cmp to compare to the PyTorch gradients. Due to numerical over/underflow,\n",
    "torch.all may return False, but as long as torch.allclose returns True we \n",
    "should be confident the gradients are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_grad     | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_8_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_7_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_6_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_5_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_4_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_3_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_2_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "h_1_grad        | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "c_grad          | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "b_grad          | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "V_grad          | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "W_grad          | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "U_grad          | exact: False | approximate: True  | maxdiff: 0.000000\n",
      "C_grad          | exact: False | approximate: True  | maxdiff: 0.000000\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Compute gradients\n",
    "    one_hot = F.one_hot(yb, num_classes=vocab_size).float()\n",
    "    dlogits = (1/block_size) * (F.softmax(logits, dim = -1) - one_hot) \n",
    "\n",
    "    dhT = dlogits[:, -1, :] @ V\n",
    "    dhs = [dhT]\n",
    "    for i in range(1, block_size):\n",
    "        dhs.append(dhs[i - 1] @ torch.diag((1 - intermediate_tensors[-i] ** 2).view(-1)) @ W + dlogits[:, -(i + 1), :] @ V)\n",
    "\n",
    "    dc = dlogits.sum(dim = 1)\n",
    "\n",
    "    db = torch.zeros_like(b.view(1, -1))\n",
    "    for i in range(block_size):\n",
    "        db += dhs[i] @ torch.diag((1 - intermediate_tensors[-(i + 1)] ** 2).view(-1))\n",
    "\n",
    "    dV = torch.zeros_like(V)\n",
    "    for i in range(block_size):\n",
    "        dV += dlogits[:, i, :].T @ intermediate_tensors[i]\n",
    "\n",
    "    intermediate_tensors_2 = [model.h_0] + intermediate_tensors # include h_0\n",
    "    dW = torch.zeros_like(W)\n",
    "    for i in range(block_size):\n",
    "        dW += (dhs[-(i + 1)] * (1 - intermediate_tensors_2[i + 1] ** 2)).T @ intermediate_tensors_2[i]\n",
    "\n",
    "    dU = torch.zeros_like(U)\n",
    "    for i in range(block_size):\n",
    "        dU += (dhs[-(i + 1)] * (1 - intermediate_tensors[i] ** 2)).T @ intermediate_embeddings[i]\n",
    "\n",
    "    dC = torch.zeros_like(C)\n",
    "    for t in range(block_size):\n",
    "        da_t = dhs[-(t + 1)].view(-1) * (1 - intermediate_tensors[t] ** 2).view(-1)\n",
    "        dx_t = da_t @ U  # all emb_grads\n",
    "        idx = xb.view(-1)[t]\n",
    "        dC[idx, :] += dx_t\n",
    "\n",
    "    # Compare gradients\n",
    "    cmp(\"logits_grad\", dlogits, logits)\n",
    "    for i in range(block_size):\n",
    "        string = f\"h_{block_size - i}_grad\"\n",
    "        cmp(string, dhs[i], intermediate_tensors[-(i + 1)])\n",
    "    cmp(\"c_grad\", dc, c)\n",
    "\n",
    "    cmp(\"b_grad\", db, b)\n",
    "    cmp(\"V_grad\", dV, V)\n",
    "    cmp(\"W_grad\", dW, W)\n",
    "    cmp(\"U_grad\", dU, U)\n",
    "    cmp(\"C_grad\", dC, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
